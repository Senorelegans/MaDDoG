
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/10_DogcatcherFlatten.ipynb
import pandas as pd
import argparse
import csv
import os

import numpy as np
import string

def FivePrimeArea(df):
    df = df.sort_values(by=["chr","end"],ascending=True)
    df["FA_start"] = df["gene_start"]
    df_exon = df[df["type"]=="exon"].copy()
    df_exon = df_exon.drop_duplicates(subset=['name'],keep="first")
    df_exon["FA_end"] = df_exon["end"]
    df_exon = df_exon[["name","FA_end"]]
    df = pd.merge(df,df_exon,how="left",on="name")
    df["FA_length"] = df["FA_end"] - df["FA_start"]
    df = df.drop_duplicates(subset=['name'],keep="first")
    return df


def ThreePrimeArea(df):
    df = df.sort_values(by=["chr","end"],ascending=False)
    df["LA_end"] = df["gene_end"]
    df_exon = df[df["type"]=="exon"].copy()
    # Keep first exon
    df_exon = df_exon.drop_duplicates(subset=['name'],keep="first")
    df_exon["LA_start"] = df_exon["start"]
    df_exon = df_exon[["name","LA_start"]]
    df = pd.merge(df,df_exon,how="left",on="name")
    df["LA_length"] = df["LA_end"] - df["LA_start"]
    df = df.drop_duplicates(subset=['name'],keep="first")
    return df


def getAreas(df):
    """
    This function will get the first and last exons for plu and min strand.
    Call it area because not necessarily exon.
    """

    df_plu = df[df["strand"]=="+"]
    df_min = df[df["strand"]=="-"]
    df_plu_FA = FivePrimeArea(df_plu)
    df_min_FA = FivePrimeArea(df_min)
    df_plu_LA = ThreePrimeArea(df_plu)[["name","LA_start","LA_end","LA_length"]]
    df_min_LA = ThreePrimeArea(df_min)[["name","LA_start","LA_end","LA_length"]]
    df_plu = pd.merge(df_plu_FA,df_plu_LA,on="name")
    df_min = pd.merge(df_min_FA,df_min_LA,on="name")
    df = pd.concat([df_plu,df_min])
    return df


def chrDIC(df):
    """This function will take a gtf and return strand specific dictionary of different chrm"""
    chr_names=df['chr'].unique().tolist()
    d_chr = d_gtf_chr = {chrom : df[df["chr"]==chrom] for chrom in chr_names}
    return d_chr

def countInside(df, start, end):
    rows_df = df[ (start < df["start"]) & (df["end"] < end) ]
    names = rows_df['name'].unique().tolist()
    names = ",".join(names)
    if len(names) >0:
        return names
    else:
        return np.nan

def removeInside(df):
    d_chr = chrDIC(df)

    df['genes_inside'] = df.apply(lambda row: countInside(d_chr[row['chr']], row["start"], row["end"]), axis=1)
    df2 = df.dropna(subset=['genes_inside'])
    all_names = []
    for i in range(len(df2)):
        names = df2["genes_inside"].iloc[i]
        names = names.split(",")
        all_names = all_names + names

    inside_genes = list(set(all_names))
    l = len(inside_genes)
    print(f"Removing {l} genes that are inside other genes")

    df_inside = pd.DataFrame(inside_genes,columns=['name'])
    df = df[~df["name"].isin(df_inside["name"])].copy()
    del df["genes_inside"]

    return df, df_inside

def flattenGTF(file_in,file_type,NEXTFLOW=True):
    if file_type == "ENSEMBL":
        print(f"Flattening ENSEMBL like genome {file_in}")
        my_col = ["chr","source","type","start","end","dot","strand","dot2","gene_id"]

        df = pd.read_csv(file_in, sep="\t",header=None,names=my_col, comment="#",low_memory=False)

        df["chr"] = df["chr"].astype(str)
        df = df[~df["chr"].str.contains("\.") ]    # Take out patches

        df.sort_values(by=["chr","start"], inplace=True, ascending=True)
        fout = f"{file_in[:-4]}_sort.gtf"
        df.to_csv(fout,sep="\t", index=None,quoting=csv.QUOTE_NONE, header=None)


        df["name"] = df["gene_id"].str.split(';',expand=True)[0]
        df["name"] = df["name"].str.replace("gene_id ","")
        df["name"] = df["name"].str.replace("\"","")

        df["type"] = df["type"].astype(str)

        df_gene = df[df["type"]=="gene"].copy()
        df_gene["gene_start"] = df_gene["start"]
        df_gene["gene_end"] = df_gene["end"]

        df_gene = df_gene[["name","gene_start","gene_end"]].copy()
        df = pd.merge(df,df_gene,how="left",on="name")
        df = getAreas(df)
        df["start"] = df["gene_start"]
        df["end"] = df["gene_end"]
#                 df = df[["chr","start","end","strand","name","type"]].copy()


    if file_type == "BED":
        my_col = ["chr","start","end","name","strand"]
        df = pd.read_csv(file_in, sep="\t",header=None,names=my_col, comment="#",low_memory=False)
        df["FA_start"] = df["start"]
        df["FA_end"] = df["end"]
        df["LA_start"] = df["start"]
        df["LA_end"] = df["end"]
        df["dot"] = "."
        df["dot2"] = "."
        df["source"] = "NA"
        df["type"] = "NA"
        df["gene_id"] = df["name"]




    if file_type == "REFSEQGFF":

        # Chrome numbers are changed. Need to change back to chr1 etc.
#         https://www.ncbi.nlm.nih.gov/assembly/GCF_000001405.39#/def_asm_Primary_Assembly
        print(f"Flattening  REFSEQGFF like genome")
#         https://ftp.ncbi.nlm.nih.gov/genomes/refseq/vertebrate_mammalian/Homo_sapiens/reference/
        #download this GCF_000001405.39_GRCh38.p13_genomic.gtf.gz
    # sort and index in IGV
#     NC_000001.11	BestRefSeq	gene	11874	14409	.	+	.	gene_id "DDX11L1"; transcript_id ""; db_xref "GeneID:100287102"; db_xref "HGNC:HGNC:37102"; description "DEAD/H-box helicase 11 like 1 (pseudogene)"; gbkey "Gene"; gene "DDX11L1"; gene_biotype "transcribed_pseudogene"; pseudo "true";



        my_col = ["chr","source","type","start","end","dot","strand","dot2","gene_id"]

        replace_list = [("chr1","NC_000001.11"),
        ("chr2","NC_000002.12"),
        ("chr3","NC_000003.12"),
        ("chr4","NC_000004.12"),
        ("chr5","NC_000005.10"),
        ("chr6","NC_000006.12"),
        ("chr7","NC_000007.14"),
        ("chr8","NC_000008.11"),
        ("chr9","NC_000009.12"),
        ("chr10","NC_000010.11"),
        ("chr11","NC_000011.10"),
        ("chr12","NC_000012.12"),
        ("chr13","NC_000013.11"),
        ("chr14","NC_000014.9"),
        ("chr15","NC_000015.10"),
        ("chr16","NC_000016.10"),
        ("chr17","NC_000017.11"),
        ("chr18","NC_000018.10"),
        ("chr19","NC_000019.10"),
        ("chr20","NC_000020.11"),
        ("chr21","NC_000021.9"),
        ("chr22","NC_000022.11"),
        ("chrX","NC_000023.11"),
        ("chrY","NC_000024.10")]


        df = pd.read_csv(file_in, sep="\t",header=None,names=my_col, comment="#",low_memory=False)

        df = df[df["type"]=="gene"].copy()

        # Change NC names to chr
        for l in replace_list:
            df["chr"] = np.where(df["chr"]==l[1],l[0],df["chr"])

        df = df[~df["chr"].str.contains("\.") ]    # Take out patches


        df["name"] = df["gene_id"].str.split(';',expand=True)[0]
        df["name"] = df["name"].str.replace("ID=gene-","")

        df["type"] = df["type"].astype(str)

        df_gene = df[df["type"]=="gene"].copy()
        df_gene["gene_start"] = df_gene["start"]
        df_gene["gene_end"] = df_gene["end"]

        df_gene = df_gene[["name","gene_start","gene_end"]].copy()
        df = pd.merge(df,df_gene,how="left",on="name")
        df = getAreas(df)
        df["start"] = df["gene_start"]
        df["end"] = df["gene_end"]
#                 df = df[["chr","start","end","strand","name","type"]].copy()







    if file_type == "REFSEQBED":

#         chr1	11873	14409	NR_046018	0	+	
# 14409	14409	0	3	354,109,1189,	0,739,1347,


        my_col = ["chr","start","end","name","dot","strand","start1","start2","dot2","dot3","gene_id","gene_id2"]

        df = pd.read_csv(file_in, sep="\t",header=None,names=my_col, comment="#",low_memory=False)
        df = df[["chr","start","end","name","strand"]]
        df["FA_start"] = df["start"]
        df["FA_end"] = df["end"]
        df["LA_start"] = df["start"]
        df["LA_end"] = df["end"]
        df["dot"] = "."
        df["dot2"] = "."
        df["source"] = "NA"
        df["type"] = "NA"
        df["gene_id"] = df["name"]



    df_plu = df[df["strand"]=="+"].copy()
    df_min = df[df["strand"]=="-"].copy()

    df_plu, df_plu_inside = removeInside(df_plu)
    df_min, df_min_inside = removeInside(df_min)

    df_plu.sort_values(by=["chr","end"], inplace=True, ascending=False)
    df_plu.drop_duplicates(subset=["start","chr"], keep='first', inplace=True)

    df_min.sort_values(by=["chr","start"], inplace=True, ascending=True)
    df_min.drop_duplicates(subset=["end","chr"], keep='first', inplace=True)


    df = pd.concat([df_plu,df_min])
    df = df.sort_values(by=["chr","end"],ascending=False)


    gtf = df[["chr","source","type","start","end","dot","strand","dot2","gene_id"]  ]
    df = df[["chr","start","end","name","strand","FA_start","FA_end","LA_start","LA_end"]]


    if NEXTFLOW:
        file_in = os.path.basename(file_in)

    fout = f"{file_in[:-4]}_flat.txt"
    fout2 = f"{file_in[:-4]}_flat.gtf"
    fout3 = f"{file_in[:-4]}_flat_CHROMNAMES.txt"



    print(f"Outputting flat file {fout}")
    df.to_csv(fout,sep="\t",index=None)


    gtf.to_csv(fout2,sep="\t", index=None,quoting=csv.QUOTE_NONE, header=None)

    gtf_names = gtf[["chr"]].copy()
    gtf_names.drop_duplicates(subset=["chr"], keep='first', inplace=True)

    gtf_names.to_csv(fout3,sep="\t", index=None)

    return df


import argparse
def parse_arguments():
        parser = argparse.ArgumentParser(description='Flatten gtf or bed to first and last exon file. Options in currently are ENSEMBL, BED')
        parser.add_argument('--annotation_in', action= 'store', metavar='annotation_in')
        parser.add_argument('--file_type', action= 'store', metavar='file_type',default="ENSEMBL")
        args = parser.parse_args()
        return args

if __name__=="__main__":
    args = parse_arguments()
    file_in = args.annotation_in
    file_type = args.file_type

    flattenGTF(file_in,file_type)
