{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T19:30:48.539260Z",
     "start_time": "2019-08-16T19:30:35.705917Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T19:30:54.575521Z",
     "start_time": "2019-08-16T19:30:48.541017Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from nb_00 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T19:30:54.607510Z",
     "start_time": "2019-08-16T19:30:54.577587Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def parseMatchFamClass(line):\n",
    "        line = ' '.join(line.split()) +\"\\n\"\n",
    "        L = line.split(\" \")\n",
    "        Lstart = L[:10]\n",
    "        Lend = L[11:]\n",
    "        class_fam = L[10]\n",
    "        match = L[9]\n",
    "        if \"/\" not in class_fam:\n",
    "            class_fam = [f'{class_fam}',f'{class_fam}']\n",
    "        else:\n",
    "            class_fam = class_fam.split(\"/\")\n",
    "        cla = class_fam[0]\n",
    "        family = class_fam[1]\n",
    "        name = [f'{match}|{family}|{cla}']\n",
    "        \n",
    "        L = Lstart+ name+class_fam+Lend\n",
    "        line = \"\\t\".join(L)\n",
    "        return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T19:30:54.641171Z",
     "start_time": "2019-08-16T19:30:54.609383Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def writeFiltered(line, removelist,outfile2,outfile3):\n",
    "    WRITE = True\n",
    "    for r in removelist:\n",
    "        if r in line:\n",
    "            WRITE=False\n",
    "            outfile3.write(line)\n",
    "    if WRITE:\n",
    "        outfile2.write(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T19:30:54.689029Z",
     "start_time": "2019-08-16T19:30:54.642920Z"
    },
    "code_folding": [
     39
    ]
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def flankFasta(df,num):\n",
    "    df = df[df[\"start\"]>num]\n",
    "    df[\"L_fa\"] = df[\"extrafasta\"].str[0:num]\n",
    "    df[\"R_fa\"] = df[\"extrafasta\"].str[-num:]\n",
    "    df[\"fa\"] = df[\"extrafasta\"].str[num:-num]\n",
    "    return df\n",
    "\n",
    "def makeFasta(df,fout,fa):\n",
    "    df2 = pd.DataFrame()\n",
    "    df2[\"data\"] = \">\"+df[\"data\"]\n",
    "    df2[fa] = df[fa]\n",
    "    df2.to_csv(f'{fout}_flank_{fa}.fa',sep=\"\\n\",index=None,header=False)\n",
    "    removeAndZip(f\"gzip {fout}_flank_{fa}.fa\")\n",
    "\n",
    "def parseFasta(f, folderout):\n",
    "    f = Path(f)\n",
    "    fout = f'{folderout}/{f.stem}'\n",
    "    \n",
    "    df = pd.read_csv(f,sep=\"\\t\",names=[\"data\",\"fasta\"])\n",
    "    df2 = df[\"data\"].str.rsplit(\";\", expand=True)\n",
    "    D = df2[0].str.rsplit(\"|\", expand=True)\n",
    "    df[\"chr\"] = D[0].str.rsplit(\"=\", expand=True)[1]\n",
    "    df[\"start\"] = D[1].astype(int)\n",
    "    df[\"stop\"] = D[2].astype(int)\n",
    "    D = df2[1].str.rsplit(\"=\", expand=True)[1].str.rsplit(\"|\",expand=True)\n",
    "    print(df.head())\n",
    "    df[\"name\"] = df2[3].str.rsplit(\"=\", expand=True)[1]\n",
    "    D3 = df[\"name\"].str.rsplit(\"|\", expand=True)\n",
    "    df[\"MR\"] = D3[0]\n",
    "    df[\"FAMILY\"] = D3[1]\n",
    "    df[\"CLASS\"] = D3[2]\n",
    "    df[\"strand\"] = df2[4].str.rsplit(\"=\", expand=True)[1].str.replace(\"(\",\"\").str.replace(\")\",\"\")\n",
    "#     df = flankFasta(df,10000)\n",
    "    makeFasta(df,fout,fa=\"fasta\")\n",
    "    df= df[[\"chr\",\"start\",\"stop\",\"wstart\",\"wstop\",\"name\",\"MR\",\"FAMILY\",\"CLASS\",\"strand\",\"fasta\"]]\n",
    "    df.to_csv(fout+\".txt\",sep=\"\\t\",index=None)\n",
    "#     removeAndZip(f'{fout}_.txt')\n",
    "\n",
    "def parseFastaExtra(f,num, folderout):\n",
    "    f = Path(f)\n",
    "    fout = f'{folderout}/{f.stem}'\n",
    "    \n",
    "    df = pd.read_csv(f,sep=\"\\t\",names=[\"data\",\"extrafasta\"])\n",
    "    df2 = df[\"data\"].str.rsplit(\";\", expand=True)\n",
    "    D = df2[0].str.rsplit(\"|\", expand=True)\n",
    "    df[\"chr\"] = D[0].str.rsplit(\"=\", expand=True)[1]\n",
    "    df[\"start\"] = D[1].astype(int)\n",
    "    df[\"stop\"] = D[2].astype(int)\n",
    "    D = df2[1].str.rsplit(\"=\", expand=True)[1].str.rsplit(\"|\",expand=True)\n",
    "    df[\"wstart\"] = D[0].astype(int)\n",
    "    df[\"wstop\"] = D[1].astype(int)\n",
    "    \n",
    "    df[\"name\"] = df2[3].str.rsplit(\"=\", expand=True)[1]\n",
    "    D3 = df[\"name\"].str.rsplit(\"|\", expand=True)\n",
    "    df[\"MR\"] = D3[0]\n",
    "    df[\"FAMILY\"] = D3[1]\n",
    "    df[\"CLASS\"] = D3[2]\n",
    "    df[\"strand\"] = df2[4].str.rsplit(\"=\", expand=True)[1].str.replace(\"(\",\"\").str.replace(\")\",\"\")\n",
    "    df = flankFasta(df,10000)\n",
    "    del df[\"extrafasta\"]\n",
    "    makeFasta(df,fout,fa=\"fa\")\n",
    "    makeFasta(df,fout,fa=\"L_fa\")\n",
    "    makeFasta(df,fout,fa=\"R_fa\")\n",
    "    df= df[[\"chr\",\"start\",\"stop\",\"wstart\",\"wstop\",\"name\",\"MR\",\"FAMILY\",\"CLASS\",\"strand\",\"fa\",\"L_fa\",\"R_fa\"]]\n",
    "    df.to_csv(fout+\"_flank.txt\",sep=\"\\t\",index=None)\n",
    "    removeAndZip(f'{fout}_flank.txt')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T19:30:54.731537Z",
     "start_time": "2019-08-16T19:30:54.690835Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def ParseRM(f,path,genome,removelist,extension=\".fa.out\",JUPYTER=False):\n",
    "    \"\"\"\n",
    "    path: this will be the path to Repeatmasker output. \n",
    "    It will search for any files in this path or folders in thie path that have the extension.\n",
    "    genome: fasta to get repetitive sequences from\n",
    "    removelist: comma seperated list of things to remove\n",
    "    JUPYTER:set to True to run test examples\n",
    "    \n",
    "    \"\"\"\n",
    "    # If running in jupyter write to RM path. Else do it in nextflow\n",
    "    if JUPYTER:\n",
    "        folderout = f'{path}/ParsedRepeatMaskerGFF'\n",
    "        makeFolders([folderout])\n",
    "    else:\n",
    "        folderout = \".\"\n",
    "        \n",
    "\n",
    "    genomename = Path(f).stem[:-3] # Remove extra .fa\n",
    "    outname = f'{folderout}/{genomename}'\n",
    "    \n",
    "\n",
    "    rlist = \"-\".join(removelist)\n",
    "    fout = f'{outname}.out'\n",
    "    open(fout, \"w\").write(\"\")\n",
    "    foutRNA = f'{outname}_cleaned-{rlist}.out'\n",
    "    open(foutRNA, \"w\").write(\"\")\n",
    "    foutrem = f'{outname}_garbage-{rlist}.out'\n",
    "    open(foutrem, \"w\").write(\"\")\n",
    "    with open(fout,\"a\") as outfile1, open(foutRNA,\"a\") as outfile2, open(foutrem,\"a\") as outfile3:\n",
    "        header = \"bit score\\tperc div\\tperc del\\tperc ins\\tchr\\tstart\\tend\\tpoqleft\\tstrand\\tmatching_repeat\\tname\\tclass\\tfamily\\tpirbegin\\tpirend\\tpirleft\\tID\\n\"\n",
    "        outfile1.write(header),outfile2.write(header),outfile3.write(header)\n",
    "        with open(f,\"r\") as infile:\n",
    "            x = 0\n",
    "            for line in infile:\n",
    "                if x > 2:\n",
    "                    line = parseMatchFamClass(line)\n",
    "                    line = line.replace(\"\\t*\",\"\")\n",
    "                    writeFiltered(line,removelist,outfile2, outfile3)\n",
    "                    outfile1.write(line)\n",
    "                x += 1\n",
    "    removeAndZip(fout)  \n",
    "    removeAndZip(foutrem)\n",
    "    ##### Make bed files ####################\n",
    "    extralength = 10000\n",
    "    outlength = extralength / 1000\n",
    "    files = [fout,foutRNA,foutrem]\n",
    "    files= [foutRNA]\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f,sep=\"\\t\")\n",
    "        removeFile(f)\n",
    "        df[\"strand\"] = df[\"strand\"].replace(\"C\",\"-\")\n",
    "        df[\"dot\"] = \".\"\n",
    "        df[\"attribute\"] = \"loc=\"+df[\"chr\"]+\"|\"+df[\"start\"].astype(str)+\"|\"+df[\"end\"].astype(str)+\"|ID=\"+df[\"ID\"].astype(str)+\";name=\"+df[\"name\"]+\";strand=\"\n",
    "        df1 = df[[\"chr\",\"dot\",\"attribute\",\"start\",\"end\",\"dot\",\"strand\",\"dot\",\"attribute\"]]\n",
    "        df1.to_csv(f'{f[:-4]}.gff',sep=\"\\t\",index=None,header=None)\n",
    "        subprocess.run(f\"bedtools getfasta -tab -name -s -fi {genome} -bed {f'{f[:-4]}.gff'} > {f'{f[:-4]}.txt'}\", shell=True)\n",
    "        parseFasta(f=f'{f[:-4]}.txt', folderout=folderout)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Add extra length to sequences\n",
    "        df[\"newstart\"] = df[\"start\"] - extralength\n",
    "        df[\"newstart\"] = np.where(df[\"newstart\"]<1,1,df[\"newstart\"])\n",
    "        df[\"newend\"] = df[\"end\"] + extralength\n",
    "        df[\"attribute\"] = \"loc=\"+df[\"chr\"]+\"|\"+df[\"start\"].astype(str)+\"|\"+df[\"end\"].astype(str)+\";wideloc=\"+df[\"newstart\"].astype(str)+\"|\"+df[\"newend\"].astype(str)+\";ID=\"+df[\"ID\"].astype(str)+\";name=\"+df[\"name\"]+\";strand=\"\n",
    "        df = df[[\"chr\",\"dot\",\"attribute\",\"newstart\",\"newend\",\"dot\",\"strand\",\"dot\",\"attribute\"]]\n",
    "        \n",
    "        f_extra = f'{f[:-4]}_+-{outlength}kb.gff'\n",
    "        f_extra_out = f'{f[:-4]}_+-{outlength}kb.txt'\n",
    "        df.to_csv(f_extra,sep=\"\\t\",index=None,header=None)\n",
    "        \n",
    "#         subprocess.run(f\"bedtools getfasta -tab -name -s -fi {genome} -bed {f_extra} > {f_extra_out}\", shell=True)\n",
    "#         removeAndZip(f_extra)\n",
    "#         subprocess.run(f\"gzip {f_extra}\", shell=True)\n",
    "#         parseFasta(f=f_extra_out, folderout=folderout,num=10000)\n",
    "#         removeAndZip(f_extra_out)\n",
    "#         subprocess.run(f\"gzip {f_extra_out}\", shell=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T19:30:57.479504Z",
     "start_time": "2019-08-16T19:30:54.733338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                data  \\\n",
      "0  loc=chrX|10042|10428|ID=2;name=LTR12E|ERV1|LTR...   \n",
      "1  loc=chrX|11800|12270|ID=3;name=LTR6B|ERV1|LTR;...   \n",
      "2  loc=chrX|12291|12704|ID=4;name=LTR2C|ERV1|LTR;...   \n",
      "3  loc=chrX|13017|13271|ID=7;name=AluSg|Alu|SINE;...   \n",
      "4  loc=chrX|14909|15164|ID=8;name=MLT1A|ERVL-MaLR...   \n",
      "\n",
      "                                               fasta   chr  start   stop  \n",
      "0  AAAGTGGACCTATCAGCAGGATGTGGGTGGGAGCAGATTAGAGAAT...  chrX  10042  10428  \n",
      "1  TGTAATGCCCAACCTCATTTTTGCTAACCCTGTTTTTAGACTCTCC...  chrX  11800  12270  \n",
      "2  TAAGGGAGGAGACCGCCACTTCTGCTGCCCTTCCCTTCCCCACACC...  chrX  12291  12704  \n",
      "3  ACAGGAGGTCAGAACTTCAAGATCCTCTTGAATTTCAAGAACTACT...  chrX  13017  13271  \n",
      "4  ATGTGTTGGCAATTTAATCCCCGAATTCATGTCCTGATTGGAGATA...  chrX  14909  15164  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 3",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-926c8a453e1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mgenome\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/Users/m/Google_Drive/Scripts/IGVfiles/hg38/hg38.fa\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mremovelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Simple_repeat\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Low_complexity\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rRNA\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         JUPYTER=True)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-e0a4b88a9226>\u001b[0m in \u001b[0;36mParseRM\u001b[0;34m(f, path, genome, removelist, extension, JUPYTER)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{f[:-4]}.gff'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"bedtools getfasta -tab -name -s -fi {genome} -bed {f'{f[:-4]}.gff'} > {f'{f[:-4]}.txt'}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mparseFasta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{f[:-4]}.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolderout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfolderout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-77de0a8e5a02>\u001b[0m in \u001b[0;36mparseFasta\u001b[0;34m(f, folderout)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mD3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MR\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "ParseRM(f=\"test/RepeatMasker_test/chrX.fa.out\",\n",
    "        path=\"test/RepeatMasker_test\",\n",
    "        extension=\".fa.out\",\n",
    "        genome=\"/Users/m/Google_Drive/Scripts/IGVfiles/hg38/hg38.fa\", \n",
    "        removelist = [\"Simple_repeat\",\"Low_complexity\",\"rRNA\"], \n",
    "        JUPYTER=True)\n",
    "\n",
    "\n",
    "# ParseRM(f=\"test/RepeatMasker_test/chrY.fa.out\",\n",
    "#         path=\"test/RepeatMasker_test\",\n",
    "#         extension=\".fa.out\",\n",
    "#         genome=\"/Users/m/Google_Drive/Scripts/IGVfiles/hg38/hg38.fa\", \n",
    "#         removelist = [\"Simple_repeat\",\"Low_complexity\",\"rRNA\"], \n",
    "#         JUPYTER=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T19:30:57.481795Z",
     "start_time": "2019-08-16T19:30:39.268Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T19:30:57.483084Z",
     "start_time": "2019-08-16T19:30:40.746Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import argparse\n",
    "def parse_arguments():\n",
    "        parser = argparse.ArgumentParser(description='Checking Paired or not or if its zipped.')\n",
    "        parser.add_argument('--file', action= 'store', metavar='file') \n",
    "        parser.add_argument('--path', action= 'store', metavar='path') \n",
    "        parser.add_argument('--genome', action= 'store', metavar='genome')\n",
    "        parser.add_argument('--verbose', action= 'store', metavar='verbose', default= False) \n",
    "        parser.add_argument('--removelist', action= 'store', metavar='removelist', default= False) \n",
    "        parser.add_argument('--JUPYTER', action= 'store', metavar='JUPYTER', default= False)\n",
    "        args = parser.parse_args()\n",
    "        return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T19:30:57.484413Z",
     "start_time": "2019-08-16T19:30:41.721Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "#Ignore error, run this cell to get proper export of function\n",
    "#to python script\n",
    "if __name__==\"__main__\":\n",
    "    args = parse_arguments()\n",
    "    verbose = fix_bool(args.verbose)\n",
    "    JUPYTER = fix_bool(args.JUPYTER)\n",
    "    f = fix_bool(args.file)\n",
    "    path = args.path\n",
    "    genome = args.genome\n",
    "    removelist = args.removelist.split(\",\")\n",
    "    ParseRM(f=f,path=path, removelist = removelist, genome=genome, JUPYTER=JUPYTER)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T21:13:04.357771Z",
     "start_time": "2019-08-01T21:13:01.872497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01.1ParseRepeatMaskerOutput.ipynb to nb_01.1ParseRepeatMaskerOutput.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py 01.1ParseRepeatMaskerOutput.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T15:05:42.810085Z",
     "start_time": "2019-07-31T15:05:42.768092Z"
    }
   },
   "outputs": [],
   "source": [
    "#Test python script in bash\n",
    "#!python nb_01ParseRepeatMaskerOutput.py --path \"test/RepeatMasker_test\" --removelist \"Simple_repeat,Low_complexity,rRNA\" --genomename  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
