{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T17:35:40.210132Z",
     "start_time": "2019-07-31T17:35:31.280427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T17:35:40.558713Z",
     "start_time": "2019-07-31T17:35:40.213723Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from nb_00 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T17:35:40.612321Z",
     "start_time": "2019-07-31T17:35:40.560872Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def parseMatchFamClass(line):\n",
    "        line = ' '.join(line.split()) +\"\\n\"\n",
    "        L = line.split(\" \")\n",
    "        Lstart = L[:10]\n",
    "        Lend = L[11:]\n",
    "        class_fam = L[10]\n",
    "        match = L[9]\n",
    "        if \"/\" not in class_fam:\n",
    "            class_fam = [f'{class_fam}',f'{class_fam}']\n",
    "        else:\n",
    "            class_fam = class_fam.split(\"/\")\n",
    "        cla = class_fam[0]\n",
    "        family = class_fam[1]\n",
    "        name = [f'{match}|{family}|{cla}']\n",
    "        \n",
    "        L = Lstart+ name+class_fam+Lend\n",
    "        line = \"\\t\".join(L)\n",
    "        return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T17:35:40.649452Z",
     "start_time": "2019-07-31T17:35:40.614381Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def writeFiltered(line, removelist,outfile2,outfile3):\n",
    "    WRITE = True\n",
    "    for r in removelist:\n",
    "        if r in line:\n",
    "            WRITE=False\n",
    "            outfile3.write(line)\n",
    "    if WRITE:\n",
    "        outfile2.write(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T17:35:40.699918Z",
     "start_time": "2019-07-31T17:35:40.651391Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def ParseRM(path,genome,removelist,extension=\".fa.out\",JUPYTER=False):\n",
    "    \"\"\"\n",
    "    path: this will be the path to Repeatmasker output. \n",
    "    It will search for any files in this path or folders in thie path that have the extension.\n",
    "    genome: fasta to get repetitive sequences from\n",
    "    removelist: comma seperated list of things to remove\n",
    "    JUPYTER:set to True to run test examples\n",
    "    \n",
    "    \"\"\"\n",
    "    # If running in jupyter write to RM path. Else do it in nextflow\n",
    "    if JUPYTER:\n",
    "        folderout = f'{path}/ParsedRepeatMaskerGFF'\n",
    "        makeFolders([folderout])\n",
    "    else:\n",
    "        folderout = \".\"\n",
    "        \n",
    "\n",
    "    genomename = Path(genome).stem\n",
    "    \n",
    "    files = []\n",
    "    for folder in glob.glob(f'{path}/*'):\n",
    "        f = glob.glob(f'{folder}/*{extension}')\n",
    "        if len(f) > 0:\n",
    "            files.append(f[0])\n",
    "    if len(files) < 1:\n",
    "        files = glob.glob(f'{path}/*{extension}')\n",
    "#     print(f'files:{files}')\n",
    "            \n",
    "    rlist = \"-\".join(removelist)\n",
    "    fout = f'{folderout}/{genomename}_ALL.out'\n",
    "    open(fout, \"w\").write(\"\")\n",
    "    foutRNA = f'{folderout}/{genomename}_removed-{rlist}.out'\n",
    "    open(foutRNA, \"w\").write(\"\")\n",
    "    foutrem = f'{folderout}/{genomename}_OUT-{rlist}.out'\n",
    "    open(foutrem, \"w\").write(\"\")\n",
    "    with open(fout,\"a\") as outfile1, open(foutRNA,\"a\") as outfile2, open(foutrem,\"a\") as outfile3:\n",
    "        header = \"bit score\\tperc div\\tperc del\\tperc ins\\tchr\\tstart\\tend\\tpoqleft\\tstrand\\tmatching_repeat\\tname\\tclass\\tfamily\\tpirbegin\\tpirend\\tpirleft\\tID\\n\"\n",
    "        outfile1.write(header),outfile2.write(header),outfile3.write(header)\n",
    "        for f in files:\n",
    "#             print(f'file:{f}')\n",
    "            with open(f,\"r\") as infile:\n",
    "                x = 0\n",
    "                for line in infile:\n",
    "                    if x > 2:\n",
    "                        line = parseMatchFamClass(line)\n",
    "                        line = line.replace(\"\\t*\",\"\")\n",
    "#                         print(line)\n",
    "                        writeFiltered(line,removelist,outfile2, outfile3)\n",
    "                        outfile1.write(line)\n",
    "                    x += 1\n",
    "#     print(\"Done parsing gffs\")\n",
    "    ##### Make bed files ####################\n",
    "    extralength = 10000\n",
    "    gffs = glob.glob(f'{folderout}/*.out')\n",
    "    for f in gffs:\n",
    "#         print(f)\n",
    "        df = pd.read_csv(f,sep=\"\\t\")\n",
    "        df[\"strand\"] = df[\"strand\"].replace(\"C\",\"-\")\n",
    "        df[\"dot\"] = \".\"\n",
    "        df[\"attribute\"] = \"loc=\"+df[\"chr\"]+\"|\"+df[\"start\"].astype(str)+\"|\"+df[\"end\"].astype(str)+\"|ID=\"+df[\"ID\"].astype(str)+\";name=\"+df[\"name\"]+\";strand=\"\n",
    "        df1 = df[[\"chr\",\"dot\",\"attribute\",\"start\",\"end\",\"dot\",\"strand\",\"dot\",\"attribute\"]]\n",
    "        df1.to_csv(f'{f[:-4]}.gff',sep=\"\\t\",index=None,header=None)\n",
    "        \n",
    "        # Add extra length to sequences\n",
    "        df[\"newstart\"] = df[\"start\"] - extralength\n",
    "        df[\"newstart\"] = np.where(df[\"newstart\"]<1,1,df[\"newstart\"])\n",
    "        df[\"newend\"] = df[\"end\"] + extralength\n",
    "        df[\"attribute\"] = \"loc=\"+df[\"chr\"]+\"|\"+df[\"start\"].astype(str)+\"|\"+df[\"end\"].astype(str)+\";wideloc=\"+df[\"newstart\"].astype(str)+\"|\"+df[\"newend\"].astype(str)+\";ID=\"+df[\"ID\"].astype(str)+\";name=\"+df[\"name\"]+\";strand=\"\n",
    "        df = df[[\"chr\",\"dot\",\"attribute\",\"newstart\",\"newend\",\"dot\",\"strand\",\"dot\",\"attribute\"]]\n",
    "        df.to_csv(f'{f[:-4]}_+-{extralength}kb.gff',sep=\"\\t\",index=None,header=None)\n",
    "        \n",
    "    ################ Run bedtools to extract fastas of repetitive elements #####################\n",
    "    if JUPYTER:\n",
    "        f = gffs[0]\n",
    "        f_all = f'{f[:-4]}.gff'\n",
    "        f_all_out = f'{f[:-4]}.txt'\n",
    "        f_10kb = f'{f[:-4]}_+-{extralength}kb.gff'\n",
    "        f_10kb_out = f'{f[:-4]}_+-{extralength}kb.txt'\n",
    "        print(\"Starting bedtools to extract RE fastas\")\n",
    "        subprocess.run(f\"bedtools getfasta -tab -name -s -fi {genome} -bed {f_all} -fo {f_all_out}\", shell=True)\n",
    "        subprocess.run(f\"bedtools getfasta -tab -name -s -fi {genome} -bed {f_10kb} -fo {f_10kb_out}\", shell=True)\n",
    "        print(\"Done extracting RE fastas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T17:35:42.536933Z",
     "start_time": "2019-07-31T17:35:40.701871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting bedtools to extract RE fastas\n",
      "Done extracting RE fastas\n"
     ]
    }
   ],
   "source": [
    "ParseRM(path=\"test/RepeatMasker_test\",extension=\".fa.out\",genome=\"/Users/m/Google_Drive/Scripts/IGVfiles/hg38/hg38.fa\", removelist = [\"Simple_repeat\",\"Low_complexity\",\"rRNA\"], JUPYTER=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T17:35:42.578638Z",
     "start_time": "2019-07-31T17:35:42.539983Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import argparse\n",
    "def parse_arguments():\n",
    "        parser = argparse.ArgumentParser(description='Checking Paired or not or if its zipped.')\n",
    "        parser.add_argument('--path', action= 'store', metavar='path') \n",
    "        parser.add_argument('--genome', action= 'store', metavar='genome')\n",
    "        parser.add_argument('--verbose', action= 'store', metavar='verbose', default= False) \n",
    "        parser.add_argument('--removelist', action= 'store', metavar='removelist', default= False) \n",
    "        parser.add_argument('--JUPYTER', action= 'store', metavar='JUPYTER', default= False)\n",
    "        args = parser.parse_args()\n",
    "        return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T17:35:42.618276Z",
     "start_time": "2019-07-31T17:35:42.581286Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--path path] [--genome genome]\n",
      "                             [--verbose verbose] [--removelist removelist]\n",
      "                             [--JUPYTER JUPYTER]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/M/Library/Jupyter/runtime/kernel-238395fc-aff6-4781-842b-eb48e6748522.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "#Ignore error, run this cell to get proper export of function\n",
    "#to python script\n",
    "if __name__==\"__main__\":\n",
    "    args = parse_arguments()\n",
    "    verbose = fix_bool(args.verbose)\n",
    "    JUPYTER = fix_bool(args.JUPYTER)\n",
    "    path = args.path\n",
    "    genome = args.genome\n",
    "    removelist = args.removelist.split(\",\")\n",
    "    ParseRM(path=path, removelist = removelist, genome=genome, JUPYTER=JUPYTER)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T17:35:42.620253Z",
     "start_time": "2019-07-31T17:35:38.354Z"
    }
   },
   "outputs": [],
   "source": [
    "!python notebook2script.py 01ParseRepeatMaskerOutput.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T15:05:42.810085Z",
     "start_time": "2019-07-31T15:05:42.768092Z"
    }
   },
   "outputs": [],
   "source": [
    "#Test python script in bash\n",
    "#!python nb_01ParseRepeatMaskerOutput.py --path \"test/RepeatMasker_test\" --removelist \"Simple_repeat,Low_complexity,rRNA\" --genomename  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
